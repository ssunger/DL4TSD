{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random as npr\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_mat(TTS, choice, n = [7, 7*2, 7*4, 7*4*2, 7*4*3], p = [0], channel_use = 1):\n",
    "    \"\"\"\n",
    "    Funciton which can be easilly calle din order to implament which_mat as part of a larger function\n",
    "    \"\"\"\n",
    "    return get_mat(TTS, n[choice[0]], p[choice[1]], channel_use)\n",
    "\n",
    "def get_mat(TTS, n,p = 0, channel_use = 1):\n",
    "    \"\"\"\n",
    "    Funciton that takes in \n",
    "    TTS Tesnor of Time Serieses, and given \n",
    "    n number of period to use and\n",
    "    p  last index period to use, \n",
    "    return a covariance matrix of the data for that period in terms of the values in chanel channel_use\n",
    "    \"\"\"\n",
    "    \n",
    "    d1, d2 = TTS[0], TTS[1]\n",
    "    #insert function to partition TTS correctly\n",
    "    \n",
    "    #creating cova matrix estimation desired\n",
    "    d = [d1, d1]\n",
    "    return pd.DataFrame({\"S%d\" %i: d for i,d in  enumerate(d)}).cov()\n",
    "\n",
    "\n",
    "def cov_matrix_loss(A,B, type = 1):\n",
    "    \"\"\"\n",
    "    Get distance between matracies based either on component wise distance or using eigenvalues\n",
    "    \"\"\"\n",
    "    if type == 1:\n",
    "        return torch.sqrt(torch.sum(torch.pow(torch.log(torch.eig(A-B))),2))\n",
    "    else:\n",
    "        ind = np.triu_indices(2)\n",
    "        loss = nn.MSELoss()\n",
    "        return loss(A[ind], B[ind]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-48-a0b0dc34d812>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-48-a0b0dc34d812>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    def __init__(self, kernel = , in_channels =4,  hidden_size = 128):\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class TS_based_simple(nn.modules):\n",
    "    def __init__(self, kernel = 5, in_channels =4,  hidden_size = 128):\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        super(TS_based_picker, self).__init__(self):\n",
    "        self.downconv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = channels_in, out_channels = hidden_size, \n",
    "                      stride = 2,kernel_size = kernel, padding = pads )\n",
    "            nn.BatchNorm1d()\n",
    "            nn.ReLU()\n",
    "            nn.MaxPool1d(2)\n",
    "            )\n",
    "        self.downconv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = hidden_size, out_channels = (hidden_size/2), \n",
    "                      kernel_size = (kenrnel-2), stride = 2, padding = (pads-1) )\n",
    "            nn.BatchNorm1d()\n",
    "            nn.ReLU()\n",
    "            nn.MaxPool1d(2)\n",
    "            )\n",
    "        \n",
    "        self.downconv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = (hidden_size/2), out_channels = (hidden_size/(2**2)), \n",
    "                      kernel_size = (kenrnel-2), stride = 2, padding = (pads-1) )\n",
    "            nn.BatchNorm1d()\n",
    "            nn.ReLU()\n",
    "            nn.MaxPool1d(2)\n",
    "            )\n",
    "        \n",
    "        self.downconvLast = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels = num_outs, kernel_size = (kenrnel-2), padding = (pads-1))\n",
    "            nn.BatchNorm1d()\n",
    "            nn.ReLU()\n",
    "            nn.MaxPool1d()\n",
    "            )\n",
    "        \n",
    "        self.picker = nn.Linear()\n",
    "        \n",
    "    \n",
    "    def forward(self, input):\n",
    "        \n",
    "        input_1, input_2 = input[0], input[1]\n",
    "        \n",
    "        #run the model on the first TS\n",
    "        self.c11 = self.cov1(input_1)\n",
    "        self.c12 = self.cov2(self.c11)\n",
    "        self.c13 = self.cov3(self.c12)\n",
    "        \n",
    "        #run the model on the second TS\n",
    "        self.c21 = self.cov1(input_2)\n",
    "        self.c22 = self.cov2(self.c11)\n",
    "        self.c23 = self.cov3(self.c12)\n",
    "        \n",
    "        #concat the processed data and downconvthat\n",
    "        self.cl = self.downconvLast(torch.cat((self.c23, self.c3), dim=1))\n",
    "        \n",
    "        #concat TS based data to data representative of other info\n",
    "        self.last = self.picker\n",
    "\n",
    "class TS_based_wfactors(nn.modules):\n",
    "    def __init__(self, num_outs, kernel = 5, channels_in =4, hidden_size = 128):\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        super(TS_based_picker, self).__init__(self):\n",
    "        \n",
    "        pads  == kernel//2\n",
    "        \n",
    "        self.downconv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = channels_in, out_channels = hidden_size, \n",
    "                      stride = 2,kernel_size = kernel, padding = pads )\n",
    "            nn.BatchNorm1d()\n",
    "            nn.ReLU()\n",
    "            nn.MaxPool1d(2)\n",
    "            )\n",
    "        self.downconv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = hidden_size, out_channels = (hidden_size/2), \n",
    "                      kernel_size = (kenrnel-2), stride = 2, padding = (pads-1) )\n",
    "            nn.BatchNorm1d()\n",
    "            nn.ReLU()\n",
    "            nn.MaxPool1d(2)\n",
    "            )\n",
    "        \n",
    "        self.downconv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = (hidden_size/2), out_channels = (hidden_size/(2**2)), \n",
    "                      kernel_size = (kenrnel-2), stride = 2, padding = (pads-1) )\n",
    "            nn.BatchNorm1d()\n",
    "            nn.ReLU()\n",
    "            nn.MaxPool1d(2)\n",
    "            )\n",
    "        \n",
    "        self.downconvLast = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels = num_outs, kernel_size = (kenrnel-2), padding = (pads-1))\n",
    "            nn.BatchNorm1d()\n",
    "            nn.ReLU()\n",
    "            nn.MaxPool1d()\n",
    "            )\n",
    "        \n",
    "        self.picker = nn.Linear()\n",
    "        \n",
    "    \n",
    "    def forward(self, input):\n",
    "        \n",
    "        input_1, input_2 = input[0], input[1]\n",
    "        \n",
    "        #run the model on the first TS\n",
    "        self.c11 = self.cov1(input_1)\n",
    "        self.c12 = self.cov2(self.c11)\n",
    "        self.c13 = self.cov3(self.c12)\n",
    "        \n",
    "        #run the model on the second TS\n",
    "        self.c21 = self.cov1(input_2)\n",
    "        self.c22 = self.cov2(self.c11)\n",
    "        self.c23 = self.cov3(self.c12)\n",
    "        \n",
    "        #concat the processed data and downconvthat\n",
    "        self.cl = self.downconvLast(torch.cat((self.c23, self.c3), dim=1))\n",
    "        \n",
    "        #concat TS based data to data representative of other info\n",
    "        self.last = self.picker\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  train(args):\n",
    "    #setting up the packages\n",
    "    torch.set_num_threads(5)\n",
    "    npr.seed(args.seed)\n",
    "    dir_save_to = \"results/\" + args.dir_name\n",
    "    \n",
    "    #setting up the model\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=args.learn_rate)\n",
    "    \n",
    "    #which model to implament\n",
    "    if cnn is None:\n",
    "        if args.model == \"Mod1\":\n",
    "              mod_use = TS_based_simple(args.k_size, args.num_filters, num_colours, arg.num_in_chans)\n",
    "        elif args.model == \"Mod1wFactors\":\n",
    "              mod_use = TS_based__wfactors(args.k_size, args.num_filters, num_colours, arg.num_in_chans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {seed: 12345\n",
    "        GPU = \"TRUE\"\n",
    "        dir_name = \"trial1\"\n",
    "        learn_rate = 0.005\n",
    "        model_use = \"Mod1\"\n",
    "        num_in_chans = 4\n",
    "        args.k_size = 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_csv(\"100stocks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
