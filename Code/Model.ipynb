{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import pandas as pd\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-2-eaa2c12dd2d4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-eaa2c12dd2d4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    class TS_based_picker(nn.modules):\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def which_mat(TS, n,p = 0):\n",
    "    \n",
    "    return TS.iloc()\n",
    "\n",
    "\n",
    "class TS_based_picker(nn.modules):\n",
    "    def __init__(self, kernel = , in_channels =4,  hidden_size = 128):\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        super(TS_based_picker, self).__init__(self):\n",
    "        pads  == kernel//2\n",
    "        self.downconv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel)\n",
    "            nn.BatchNorm1d()\n",
    "            nn.ReLU()\n",
    "            nn.MaxPool1d()\n",
    "            )\n",
    "        self.downconv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size = (kenrnel-2), padding = (pads-1) )\n",
    "            nn.BatchNorm1d()\n",
    "            nn.ReLU()\n",
    "            nn.MaxPool1d()\n",
    "            )\n",
    "        \n",
    "        self.downconv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size = (kenrnel-2), padding = (pads-1))\n",
    "            nn.BatchNorm1d()\n",
    "            nn.ReLU()\n",
    "            nn.MaxPool1d()\n",
    "            )\n",
    "        \n",
    "        self.\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \n",
    "        input_1, input_2 = input[0], input[1]\n",
    "        \n",
    "        #run the model on the first TS\n",
    "        self.c11 = self.cov1(input_1)\n",
    "        self.c12 = self.cov2(self.c11)\n",
    "        self.c13 = self.cov3(self.c12)\n",
    "        \n",
    "        #run the model on the second TS\n",
    "        self.c21 = self.cov1(input_2)\n",
    "        self.c22 = self.cov2(self.c11)\n",
    "        self.c23 = self.cov3(self.c12)\n",
    "        \n",
    "        #concat the processed data\n",
    "        self.cater = torch.cat((self.c23, self.c3), dim=1)\n",
    "        \n",
    "        #\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_csv(\"100stocks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/SP500.pkl\n",
      "Downloading data from /https://raw.githubusercontent.com/ssunger/DL4TSD/master/Data%20Sets/Constituent%20Data/SP500.pkl\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'URLError' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fa3541532297>\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'urlretrieve' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fa3541532297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m data_fpath = get_file(fname='SP500.pkl',\n\u001b[1;32m     47\u001b[0m                       \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/https://raw.githubusercontent.com/ssunger/DL4TSD/master/Data%20Sets/Constituent%20Data/SP500.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                          untar=False)\n\u001b[0m\u001b[1;32m     49\u001b[0m data_fpath = get_file(fname='SP400.pkl', \n\u001b[1;32m     50\u001b[0m                          \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/https://raw.githubusercontent.com/ssunger/DL4TSD/master/Data%20Sets/Constituent%20Data/SP400.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-fa3541532297>\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'URLError' is not defined"
     ]
    }
   ],
   "source": [
    "def get_file(fname,\n",
    "             origin,\n",
    "             untar=False,\n",
    "             extract=False,\n",
    "             archive_format='auto',\n",
    "             cache_dir='data'):\n",
    "    datadir = os.path.join(cache_dir)\n",
    "    if not os.path.exists(datadir):\n",
    "        os.makedirs(datadir)\n",
    "\n",
    "    if untar:\n",
    "        untar_fpath = os.path.join(datadir, fname)\n",
    "        fpath = untar_fpath + '.tar.gz'\n",
    "    else:\n",
    "        fpath = os.path.join(datadir, fname)\n",
    "    \n",
    "    print(fpath)\n",
    "    if not os.path.exists(fpath):\n",
    "        print('Downloading data from', origin)\n",
    "\n",
    "        error_msg = 'URL fetch failure on {}: {} -- {}'\n",
    "        try:\n",
    "            try:\n",
    "                urlretrieve(origin, fpath)\n",
    "            except URLError as e:\n",
    "                raise Exception(error_msg.format(origin, e.errno, e.reason))\n",
    "            except HTTPError as e:\n",
    "                raise Exception(error_msg.format(origin, e.code, e.msg))\n",
    "        except (Exception, KeyboardInterrupt) as e:\n",
    "            if os.path.exists(fpath):\n",
    "                os.remove(fpath)\n",
    "            raise\n",
    "\n",
    "    if untar:\n",
    "        if not os.path.exists(untar_fpath):\n",
    "            print('Extracting file.')\n",
    "            with tarfile.open(fpath) as archive:\n",
    "                archive.extractall(datadir)\n",
    "        return untar_fpath\n",
    "\n",
    "    if extract:\n",
    "        _extract_archive(fpath, datadir, archive_format)\n",
    "\n",
    "    return fpath\n",
    "\n",
    "data_fpath = get_file(fname='SP500.pkl',\n",
    "                      origin='/https://raw.githubusercontent.com/ssunger/DL4TSD/master/Data%20Sets/Constituent%20Data/SP500.pkl', \n",
    "                         untar=False)\n",
    "data_fpath = get_file(fname='SP400.pkl', \n",
    "                         origin='/https://raw.githubusercontent.com/ssunger/DL4TSD/master/Data%20Sets/Constituent%20Data/SP400.pkl', \n",
    "                         untar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
