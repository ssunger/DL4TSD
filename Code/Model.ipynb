{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Modelling for the TS based Cov-Matrix Picker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from numpy import random as npr\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_mat(TTS, choice, n = [7, 7*2, 7*4, 7*4*2, 7*4*3], p = [0], channel_use = 1):\n",
    "    \"\"\"\n",
    "    Funciton which can be easilly calle din order to implament which_mat as part of a larger function\n",
    "    \"\"\"\n",
    "    return get_mat(TTS, n[choice[0]], p[choice[1]], channel_use)\n",
    "\n",
    "def get_mat(TTS, n,p = 0, channel_use = 1):\n",
    "    \"\"\"\n",
    "    Funciton that takes in \n",
    "    TTS Tesnor of Time Serieses, and given \n",
    "    n number of period to use and\n",
    "    p  last index period to use, \n",
    "    return a covariance matrix of the data for that period in terms of the values in chanel channel_use\n",
    "    \"\"\"\n",
    "    \n",
    "    d1, d2 = TTS[0], TTS[1]\n",
    "    #insert function to partition TTS correctly\n",
    "    \n",
    "    #creating cova matrix estimation desired\n",
    "    d = [d1, d1]\n",
    "    return pd.DataFrame({\"S%d\" %i: d for i,d in  enumerate(d)}).cov()\n",
    "\n",
    "\n",
    "def cov_matrix_loss(A,B, type_use = 1):\n",
    "    \"\"\"\n",
    "    Get distance between matracies based either on component wise distance or using eigenvalues\n",
    "    \"\"\"\n",
    "    if type_use == 0:\n",
    "        ind = np.triu_indices(2)\n",
    "        loss = nn.MSELoss()\n",
    "        return loss(A[ind], B[ind]) \n",
    "    \n",
    "    elif type_use == 1:\n",
    "        return torch.sqrt(torch.sum(torch.pow(torch.log(torch.eig(A-B))),2))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TS_based_simple(nn.Module):\n",
    "    def __init__(self, num_outs,\n",
    "                 kernel = 5, in_channels = 4,  hidden_size = 128):\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        super(TS_based_simple, self).__init__()\n",
    "        \n",
    "        pads = kernel // 2 \n",
    "        \n",
    "        self.downconv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = in_channels, out_channels = hidden_size, \n",
    "                      stride = 2,kernel_size = kernel, padding = pads ),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "            )\n",
    "        self.downconv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = hidden_size, out_channels = (hidden_size/2), \n",
    "                      kernel_size = (kernel-2), stride = 2, padding = (pads-1) ),\n",
    "            nn.BatchNorm1d(hidden_size/2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "            )\n",
    "        \n",
    "        self.downconv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = (hidden_size/2), out_channels = (hidden_size/(2**2)), \n",
    "                      kernel_size = (kernel-2), stride = 2, padding = (pads-1) ),\n",
    "            nn.BatchNorm1d(hidden_size/(2**2)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "            )\n",
    "        \n",
    "        self.downconvLast = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = (hidden_size/(2**2)) , out_channels = num_outs, \n",
    "                      kernel_size = (kernel-2), padding = (pads-1)),\n",
    "            nn.BatchNorm1d(),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d()\n",
    "            )\n",
    "        \n",
    "        self.picker = nn.Linear(out_channels = num_outs)\n",
    "        \n",
    "    \n",
    "    def forward(self, input):\n",
    "        \n",
    "        input_1, input_2 = input[0], input[1]\n",
    "        \n",
    "        #run the model on the first TS\n",
    "        self.c11 = self.cov1(input_1)\n",
    "        self.c12 = self.cov2(self.c11)\n",
    "        self.c13 = self.cov3(self.c12)\n",
    "        \n",
    "        #run the model on the second TS\n",
    "        self.c21 = self.cov1(input_2)\n",
    "        self.c22 = self.cov2(self.c11)\n",
    "        self.c23 = self.cov3(self.c12)\n",
    "        \n",
    "        #concat the processed data and downconvthat\n",
    "        self.cl = self.downconvLast(torch.cat((self.c23, self.c3), dim=1))\n",
    "        \n",
    "        #concat TS based data to data representative of other info\n",
    "        self.last = self.picker(self.cl)\n",
    "        \n",
    "\n",
    "class TS_based_wfactors(nn.Module):\n",
    "    def __init__(self, num_outs, kernel = 5, channels_in =4, hidden_size = 128):\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        super(TS_based_wfactors, self).__init__()\n",
    "        \n",
    "        pads  == kernel//2\n",
    "        \n",
    "        self.downconv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = channels_in, out_channels = hidden_size, \n",
    "                      stride = 2,kernel_size = kernel, padding = pads ),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "            )\n",
    "        self.downconv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = hidden_size, out_channels = (hidden_size/2), \n",
    "                      kernel_size = (kernel-2), stride = 2, padding = (pads-1) ),\n",
    "            nn.BatchNorm1d(hidden_size/2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "            )\n",
    "        \n",
    "        self.downconv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = (hidden_size/2), out_channels = (hidden_size/(2**2)), \n",
    "                      kernel_size = (kernel-2), stride = 2, padding = (pads-1)),\n",
    "            nn.BatchNorm1d(hidden_size/(2**2)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "            )\n",
    "        \n",
    "        self.downconvLast = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = (hidden_size/(2**2)) , out_channels = num_outs, \n",
    "                      kernel_size = (kernel-2), padding = (pads-1)),\n",
    "            nn.BatchNorm1d(),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d()\n",
    "            )\n",
    "        \n",
    "        self.picker = nn.Linear(in_channels = num_outs , out_channels = num_outs)\n",
    "        \n",
    "    \n",
    "    def forward(self, input):\n",
    "        \n",
    "        input_1, input_2 = input[0], input[1]\n",
    "        \n",
    "        #run the model on the first TS\n",
    "        self.c11 = self.cov1(input_1)\n",
    "        self.c12 = self.cov2(self.c11)\n",
    "        self.c13 = self.cov3(self.c12)\n",
    "        \n",
    "        #run the model on the second TS\n",
    "        self.c21 = self.cov1(input_2)\n",
    "        self.c22 = self.cov2(self.c11)\n",
    "        self.c23 = self.cov3(self.c12)\n",
    "        \n",
    "        #concat the processed data and downconvthat\n",
    "        self.cl = self.downconvLast(torch.cat((self.c23, self.c3), dim=1))\n",
    "        \n",
    "        #concat TS based data to data representative of other info\n",
    "        self.last = self.picker(self.cl)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_set(data_use, max_num_training):\n",
    "    pop\n",
    "\n",
    "def train(train_d, args, mod_use = None):\n",
    "    #setting up the packages\n",
    "    torch.set_num_threads(5)\n",
    "    npr.seed(args.seed)\n",
    "    dir_save_to = \"results/\" + args.dir_name\n",
    "    if not os.path.exists(dir_save_to):\n",
    "        os.makedirs(dir_save_to)\n",
    "    \n",
    "    \n",
    "    #type of metric to use for loss:\n",
    "    l_t = 1\n",
    "    if arg.loss_type == \"L2\":\n",
    "        l_t = 0\n",
    "    \n",
    "    \n",
    "    #which model to implament\n",
    "    if mod_use is None:\n",
    "        if args.model_use == \"Mod1\":\n",
    "              mod_use = TS_based_simple(num_outs = args.k_size) #args.num_filters, num_colours, arg.num_in_chans)\n",
    "        elif args.model_use == \"Mod1wFactors\":\n",
    "              mod_use = TS_based__wfactors(num_outs = args.k_size) #, args.num_filters, num_colours, arg.num_in_chans)\n",
    "    \n",
    "    #setting up the model's optimizaer\n",
    "    optimizer = torch.optim.Adam(mod_use.parameters(), lr=args.lrn_rate)\n",
    "    \n",
    "    #where we are going to gather data\n",
    "    hist_tr_loss = []\n",
    "    hist_tt_loss = []\n",
    "    \n",
    "    #let's start training\n",
    "    for i in range(arg.num_epochs):\n",
    "        epoch_loss = []\n",
    "        \n",
    "        for j in range(len(training_set(train_d, a))):\n",
    "            #setup optimizer\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #set up optimization\n",
    "            output_choice = mod_use(input_d)\n",
    "            CM_use = which_mat(output_choice)\n",
    "            lossing_me = cov_matrix_loss(output_chice, CM_use, l_t)\n",
    "            \n",
    "            #optimizing\n",
    "            lossing.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(lossing.data.item())\n",
    "            \n",
    "        \n",
    "        #printing some stuff\n",
    "        avg_loss = np.mean(losses)\n",
    "        train_losses.append(avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up args\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "arg = AttrDict()\n",
    "args = {\"seed\": 12345,\n",
    "        \"GPU\" : \"TRUE\",\n",
    "        \"dir_name\" : \"trial1\",\n",
    "        \"lrn_rate\" : 0.005,\n",
    "        \"model_use\" : \"Mod1\",\n",
    "        \"num_in_chans\" : 4,\n",
    "        \"k_size\" : 5,\n",
    "        \"loss_type\" : \"L2\",\n",
    "        \"num_epochs\" : 10,\n",
    "        \"max_train\" : 2*10**4,\n",
    "        \"num_filters\" : 128\n",
    "}\n",
    "arg.update(args)\n",
    "train_d = \"pickle_that_pickles\" #where are the pickleessss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new() received an invalid combination of arguments - got (float, int, int), but expected one of:\n * (torch.device device)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, torch.device device)\n * (object data, torch.device device)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-1c96b96abd78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mthe_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-126-f1bec7bfe1ee>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_d, args, mod_use)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmod_use\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_use\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Mod1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m               \u001b[0mmod_use\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTS_based_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#args.num_filters, num_colours, arg.num_in_chans)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_use\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Mod1wFactors\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m               \u001b[0mmod_use\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTS_based__wfactors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, args.num_filters, num_colours, arg.num_in_chans)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-125-272815e62a9b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_outs, kernel, in_channels, hidden_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m         self.downconv2 = nn.Sequential(\n\u001b[1;32m     20\u001b[0m             nn.Conv1d(in_channels = hidden_size, out_channels = (hidden_size/2), \n\u001b[0;32m---> 21\u001b[0;31m                       kernel_size = (kernel-2), stride = 2, padding = (pads-1) ),\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)\u001b[0m\n\u001b[1;32m    180\u001b[0m         super(Conv1d, self).__init__(\n\u001b[1;32m    181\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             False, _single(0), groups, bias)\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             self.weight = Parameter(torch.Tensor(\n\u001b[0;32m---> 38\u001b[0;31m                 out_channels, in_channels // groups, *kernel_size))\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: new() received an invalid combination of arguments - got (float, int, int), but expected one of:\n * (torch.device device)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, torch.device device)\n * (object data, torch.device device)\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "the_model = train(train_d, arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data Sets/Constituent Data/SP500.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-df2fc69fdaae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msp500\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data Sets/Constituent Data/SP500.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data Sets/Constituent Data/SP500.pickle'"
     ]
    }
   ],
   "source": [
    "sp500 = open(\"../Data Sets/Constituent Data/SP500.pickle\", 'r')\n",
    "pickle.load(sp500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"../Data Sets/\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
